{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../../shared/utilz_includez.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "from skimage import color , measure\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "import cv2 \n",
    "\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "## Non-local-means denoising Approach @microscope if not using cv2.median\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup fake webcam\n",
    "# !sudo modprobe v4l2loopback\n",
    "#### --- desktop record grab_x, grab_y\n",
    "# !ffmpeg -f x11grab -r 15 -s 960x720 -i :1 -vcodec rawvideo -pix_fmt yuv420p -threads 0 -f v4l2 /dev/video0\n",
    "#### --- file stream \n",
    "# !export VIDE0=~/Videos/webcam_sim.mp4\n",
    "# !ffmpeg -re -stream_loop -1 -i $VIDEO -map 0:v -f mpegts udp://localhost:50000\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image( img_array , plotit=True, title=None, cmapd='gray', logit=True):     \n",
    "    if logit:\n",
    "        print( f\"\\n{ '-'*7 } { title if title else type(img_array) } { '-'*7 }\" )\n",
    "        print( f\"image.shape = {img_array.shape}\" ) \n",
    "        print( f\"datatype = {img_array.dtype}\")\n",
    "        print( f\"min = {np.min(img_array)} , max = {np.max(img_array)}\\n\" )\n",
    "    if plotit:\n",
    "        if cmapd:\n",
    "            plt.imshow( img_array , cmap=cmapd)\n",
    "        else:\n",
    "            plt.imshow( img_array )\n",
    "    if plotit and title:\n",
    "        plt.title(title)\n",
    "        \n",
    "        \n",
    "        \n",
    "def fetch_image(imgpath, forceuint8=True):\n",
    "    img = io.imread( imgpath )\n",
    "    if forceuint8:\n",
    "        img = np.uint8(img)\n",
    "    if len(img.shape) > 2: ##hack gray check << TODO: channel 4 ???\n",
    "        gimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY ) \n",
    "    else:\n",
    "        gimg = img.copy()\n",
    "    return img, gimg\n",
    "    \n",
    "def grid_plot_images( imgz, titlz=None, plotit=True, logit=True, cmapd='gray', nr=1, nc=2):\n",
    "    nr = np.int( len(imgz) / nc )\n",
    "    if len(imgz) % nc != 0:\n",
    "        nr = nr+1\n",
    "    for i in range( len(imgz) ):\n",
    "        plt.subplot(nr, nc, i+1 )\n",
    "        plot_image( imgz[i], title=titlz[i] if titlz else None , plotit=plotit, logit=logit, cmapd=cmapd); \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetch list of imagez and return as dict\n",
    "def fetch_imagez_dict( imgpath_list, lbl_prefix=\"Image\", logit=False):\n",
    "    dict_cell_imagez = {} \n",
    "    for i, ip in enumerate(imgpath_list):\n",
    "        c, g = fetch_image( ip )\n",
    "        if logit:\n",
    "            print(f\"IP at {i} is okay\")\n",
    "        dict_cell_imagez[f\"{lbl_prefix} # {i}\"] = (c, g )\n",
    "        \n",
    "    return dict_cell_imagez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- openCV stuff\n",
    "\n",
    "def plot_cv2Image(img, title='Image View'):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "def plot_cv2Video(capture, title='Video View'):\n",
    "    while capture.isOpened(): ## go frame by frame\n",
    "        success, img = capture.read()\n",
    "        if success:\n",
    "            cv2.imshow( title, img)\n",
    "        if cv2.waitKey(30) & 0xFF == 27: ##ESC  # 1 == ord('q'):\n",
    "            break\n",
    "      \n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "    \n",
    "\n",
    "def cv2_video_capture(src_id, img_handler=None, title='Generic', width=640, height=480, intensity=150, logit=False):    \n",
    "    if logit:\n",
    "        print(f\"@cv2_video_capture: Starting '{title}' with img_handler as {img_handler}\" ) \n",
    "            \n",
    "    cap = cv2.VideoCapture( src_id ) \n",
    "    cap.set(3, width) ##width is id 3\n",
    "    cap.set(4, height) ##height is id 4\n",
    "    cap.set(10, intensity)\n",
    "    \n",
    "    while cap.isOpened(): ## go frame by frame\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            if img_handler: \n",
    "                frame = img_handler( frame , logit)\n",
    "            else:\n",
    "                _ = cv2.putText(frame, \n",
    "                                f'NOOP@img_handler={img_handler}',\n",
    "                               (20,40), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, \n",
    "                                1, (0,0,255), 2) \n",
    "            cv2.imshow( title, frame)\n",
    "        if cv2.waitKey(30) & 0xFF == 27: ##ESC  # 1 == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "## Seek contour and bounding box of the object\n",
    "def get_contour_box(mask_img, out_img, athresh=500, tfact=0.02):\n",
    "    contz, hier = cv2.findContours(mask_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE ) \n",
    "    appx_list = []\n",
    "    for c in contz:\n",
    "        a = cv2.contourArea( c )\n",
    "        if a > athresh:\n",
    "            cv2.drawContours( out_img, c, -1, (200,0,255), 3)\n",
    "            peri = cv2.arcLength(c, True )\n",
    "            appx = cv2.approxPolyDP(c, tfact*peri, True)\n",
    "            appx_list.append( appx )\n",
    "    ## return tip of object\n",
    "    return appx_list\n",
    "    \n",
    "\n",
    "## Preprocess for edges\n",
    "def cv2_preprocess_edges(img, kern=(5,5), blursig=1, dil_iterz=1, canny_thresh1=200, canny_thresh2=200):    \n",
    "    gimg = img.copy()\n",
    "    \n",
    "    # b. grayscale it for filterz\n",
    "    if len( img.shape) > 2: ##hack check if grayscale\n",
    "        gimg = cv2.cvtColor( img, cv2.COLOR_BGR2GRAY )\n",
    "       \n",
    "    \n",
    "    # c. blur and edge detect\n",
    "    img_edgez = cv2.Canny( cv2.GaussianBlur(gimg, kern, blursig), canny_thresh1, canny_thresh2)\n",
    "    img_edgez = cv2.erode( \n",
    "            cv2.dilate(img_edgez, np.ones(kern), iterations=dil_iterz), \n",
    "            np.ones(kern), iterations=1)\n",
    "    \n",
    "    return img_edgez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warp image to get bird's eye view\n",
    "def reshape_box_approx(bbox):\n",
    "    tmp_ptz = bbox.reshape( (4,2) )\n",
    "    \n",
    "    ptz = np.zeros( (4,1,2), np.int32 )\n",
    "    \n",
    "    ## use sum to identify origins as the smallest and (x+w,y+h) as the largest\n",
    "    sumz = tmp_ptz.sum(axis=1)\n",
    "    #print( f'Sumz = {sumz}')\n",
    "    ## use diff to identify w and h size\n",
    "    diffz = np.diff(tmp_ptz, axis=1)\n",
    "    #print( f'Diffz = {diffz}')\n",
    "        \n",
    "    ptz[0] = tmp_ptz[ np.argmin(sumz) ] ## origin\n",
    "    ptz[3] = tmp_ptz[ np.argmax(sumz) ] ## endpoint (origin + (w,h))\n",
    "    ptz[1] = tmp_ptz[ np.argmin(diffz) ] ## w\n",
    "    ptz[2] = tmp_ptz[ np.argmax(diffz) ] ## h     \n",
    "    #print( f\"MAP:\\n{ptz}\\n<<<<<<< END\")\n",
    "    \n",
    "    return ptz\n",
    "\n",
    "def get_warp_perspective(img, biggest_approx, imgW=480, imgH=640):     \n",
    "    #print( \">>>> \", biggest_approx , \"\\n\")    \n",
    "    pts1 = np.float32( reshape_box_approx(biggest_approx) )\n",
    "    pts2 = np.float32([[0,0], [imgW,0], [0, imgH], [imgW, imgH]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    warped_img = cv2.warpPerspective(img, matrix, (imgW, imgH) )    \n",
    "               \n",
    "    # e. crop edges to clean up\n",
    "    w, h, *_ = warped_img.shape \n",
    "    warped_img = warped_img[ edge_margin:w-edge_margin, edge_margin:h-edge_margin]\n",
    "    # f.resize to fit screen\n",
    "    _ = cv2.resize(warped_img, (imgW, imgH) )\n",
    "    \n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_channel = 2\n",
    "\n",
    "def nuclei_channel_only(img):\n",
    "    return img[:, :, blue_channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gaussian kernel creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1feb4133e0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## clean, segment using watershed and generate properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpixels_to_um\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "## clean, segment using watershed and generate properties\n",
    "kern = np.ones( (3,3), dtype=np.uint8 )\n",
    "\n",
    "pixels_to_um = 0.5 \n",
    "\n",
    "radianz = 57.2958\n",
    "\n",
    "\n",
    "region_propz = ['Label', \"Area\", \"Perimeter\", \n",
    "     \"equivalent_diameter\", \"orientation\",\n",
    "    \"MajorAxisLength\", \"MinorAxisLength\",\n",
    "     \"MinIntensity\", \"MaxIntensity\", \"MeanIntensity\",\n",
    "    ]\n",
    "propz_addz = [\"Area_nm\", \"Perimeter_nm\", \n",
    "     \"equivalent_diameter_nm\", \n",
    "    \"orientation_degrees\",\n",
    "    \"MajorAxisLength_nm\", \"MinorAxisLength_nm\",]\n",
    "\n",
    "\n",
    "def nonlocalmeans_clean(gimg, hfactz=1.15, patchz=5, patch_distz=3, fastz=False):\n",
    "    sig = np.mean( estimate_sigma(gimg, multichannel=True) ) \n",
    "    oimg = denoise_nl_means(gimg, h=hfactz*sig, fast_mode=fastz, patch_size=patchz, patch_distance=patch_distz, multichannel=True)\n",
    "    return oimg #np.astype(oimg, np.uint8)\n",
    "\n",
    "def clean_prepare_binary( gimg , blursize=3):\n",
    "    # a. binary threshold \n",
    "    otsu, timg = cv2.threshold(gimg, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    # b. erode dilate @ crispier grains\n",
    "    timg = cv2.erode( timg, kern, iterations=1)\n",
    "    timg = cv2.dilate( timg, kern, iterations=1)\n",
    "\n",
    "    # c. median blur pixeletation << should this go first \n",
    "    timg = cv2.medianBlur(timg, blursize)\n",
    "    \n",
    "    return timg\n",
    "\n",
    "def watershed_segment(cimg, gimg, thresh_val=0.2, kern=np.ones((3,3), dtype=np.uint8), iterz=1, dilate_iterz=1 ): \n",
    "    # a. morphological extra \n",
    "    mimg = cv2.morphologyEx( gimg, cv2.MORPH_OPEN, kern, iterations=iterz)\n",
    "    \n",
    "    # b. clear border cells/grains at this point \n",
    "    mimg = clear_border( mimg )\n",
    "    \n",
    "    # c. Identify sure foreground pixels     \n",
    "    sure_bg = cv2.dilate( mimg, kern, iterations=dilate_iterz) \n",
    "    mimg = cv2.distanceTransform( mimg, cv2.DIST_L2, 3)\n",
    "    \n",
    "    # d.  Threshold\n",
    "    _, sure_fg = cv2.threshold(mimg, thresh_val*mimg.max(),  255, 0)\n",
    "    sure_fg = np.uint8( sure_fg )\n",
    "    \n",
    "    # e. gen markers and distinguish unkownz from background \n",
    "    _, markerz = cv2.connectedComponents( sure_fg )\n",
    "    \n",
    "    unknownz = cv2.subtract( sure_bg, sure_fg)\n",
    "    markerz = markerz+10\n",
    "    markerz[ unknownz == 255 ] = 0 \n",
    "    \n",
    "    # f. watershed\n",
    "    watershed = cv2.watershed( cimg, markerz )\n",
    "\n",
    "    ready_img = cimg.copy()\n",
    "    ready_img[ markerz == -1] = [0, 255, 255]\n",
    "    rimg2 = color.label2rgb( markerz, bg_label=0 )\n",
    "    \n",
    "    ## return markerz, rgb labeled images\n",
    "    return markerz, rimg2\n",
    "\n",
    "def gen_properties(markerz, gimg): \n",
    "    clusterz = measure.regionprops(markerz, intensity_image=gimg)\n",
    "    g = clusterz[0]\n",
    "    \n",
    "    ## Create dframe for it\n",
    "    dd = []\n",
    "    for g in clusterz:\n",
    "        gl = []\n",
    "        for p in region_propz:\n",
    "            gl.append( g[p] )\n",
    "\n",
    "        for ap in propz_addz:\n",
    "            p = \"_\".join( ap.split(\"_\")[:-1])\n",
    "\n",
    "            ## Area_nm\n",
    "            if( p == 'Area'):\n",
    "                gl.append( g[p] * pixels_to_um**2 )\n",
    "            ## Orientation_nm\n",
    "            elif( p == 'orientation'):\n",
    "                gl.append( g[p]* radianz ) \n",
    "            ## anything that's not Intensity\n",
    "            else:\n",
    "                gl.append( g[p]* pixels_to_um ) \n",
    "\n",
    "\n",
    "    dd.append( gl )\n",
    "    \n",
    "    # df = pd.DataFrame.from_records( dd , columns=propz+addz )\n",
    "    ## return list oobject \n",
    "    return dd\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descriptors and Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fourier Transform\n",
    "def run_discrete_fourier_transform(gimg):    \n",
    "    ## a. generate dft \n",
    "    dft = cv2.dft( np.float32(gimg), flags=cv2.DFT_COMPLEX_OUTPUT )\n",
    "\n",
    "    ## b. by default data is centered around the origin and the origin is at top left corner. So move the origin to the center of the grid\n",
    "    # shift the zero frequency to center\n",
    "    dft = np.fft.fftshift( dft)\n",
    "\n",
    "    ## c. compute the magnitude spectrum \n",
    "    kil_zero = 0\n",
    "    dft_ms = 20 * np.log( (cv2.magnitude(dft[:,:,0], dft[:,:,1]) )+kil_zero )# +1 to avoid div by zero error\n",
    "    \n",
    "    return dft, dft_ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
